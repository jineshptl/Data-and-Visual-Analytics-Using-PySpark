{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5905a69",
   "metadata": {},
   "source": [
    "# CSE6242 - HW3 - Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc5717e-fb7f-415c-ae02-16459c544fa4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    WARNING: Do <strong>NOT</strong> remove any comment that says \"#export\" because that will crash the autograder in Gradescope. We use this comment to export your code in these cells for grading.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09289981",
   "metadata": {},
   "source": [
    "Pyspark Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139318cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "### DO NOT MODIFY THIS CELL ###\n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import hour, when, col, date_format, to_timestamp, ceil, coalesce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd9e0f8",
   "metadata": {},
   "source": [
    "Initialize PySpark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c18c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT MODIFY THIS CELL ###\n",
    "sc = pyspark.SparkContext(appName=\"HW3-Q1\")\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68ae314",
   "metadata": {},
   "source": [
    "Define function for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5bbdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT MODIFY THIS CELL ###\n",
    "def load_data():\n",
    "    df = sqlContext.read.option(\"header\",True) \\\n",
    "     .csv(\"yellow_tripdata_2019-01_short.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d52409d",
   "metadata": {},
   "source": [
    "### Q1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43f6e00",
   "metadata": {},
   "source": [
    "Perform data casting to clean incoming dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f801b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def clean_data(df):\n",
    "    '''\n",
    "    input: df a dataframe\n",
    "    output: df a dataframe with the all the original columns\n",
    "    '''\n",
    "    \n",
    "    # START YOUR CODE HERE ---------\n",
    "    from pyspark.sql.functions import col, ceil, avg\n",
    "    df =df.withColumn(\"passenger_count\",col(\"passenger_count\").cast('integer'))\n",
    "    df =df.withColumn(\"total_amount\",col(\"total_amount\").cast('float'))\n",
    "    df =df.withColumn(\"tip_amount\",col(\"tip_amount\").cast('float'))\n",
    "    df =df.withColumn(\"trip_distance\",col(\"trip_distance\").cast('float'))\n",
    "    df =df.withColumn(\"fare_amount\",col(\"fare_amount\").cast('float'))\n",
    "    df =df.withColumn(\"tpep_pickup_datetime\",col(\"tpep_pickup_datetime\").cast('timestamp'))\n",
    "    df =df.withColumn(\"tpep_dropoff_datetime\",col(\"tpep_dropoff_datetime\").cast('timestamp'))\n",
    "\n",
    "    # END YOUR CODE HERE -----------\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f565d0",
   "metadata": {},
   "source": [
    "### Q1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b4f712",
   "metadata": {},
   "source": [
    "Find rate per person for based on how many passengers travel between pickup and dropoff locations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e115152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def common_pair(df):\n",
    "    '''\n",
    "    input: df a dataframe\n",
    "    output: df a dataframe with following columns:\n",
    "            - PULocationID\n",
    "            - DOLocationID\n",
    "            - total_passenger_count\n",
    "            - per_person_rate\n",
    "            \n",
    "    per_person_rate is the total_amount per person for a given pair.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # START YOUR CODE HERE ---------\n",
    "    from pyspark.sql.functions import col, avg, sum\n",
    "    \n",
    "    # Filter out trips where pickup and dropoff locations are the same\n",
    "    df = df.filter(col(\"PULocationID\") != col(\"DOLocationID\"))\n",
    "    \n",
    "    # Group by pickup and dropoff locations, summing total passengers and total amount\n",
    "    df = df.groupBy(\"PULocationID\", \"DOLocationID\").agg(\n",
    "        sum(\"passenger_count\").alias(\"total_passenger_count\"),\n",
    "        (sum(\"total_amount\") / sum(\"passenger_count\")).alias(\"per_person_rate\")\n",
    "    )\n",
    "    \n",
    "    # Sort by total passengers in descending order, then by per_person_rate in descending order\n",
    "    df = df.orderBy(col(\"total_passenger_count\").desc(), col(\"per_person_rate\").desc())\n",
    "    \n",
    "    # Select the top 10 location pairs\n",
    "    df = df.limit(10)\n",
    "    \n",
    "    \n",
    "    # END YOUR CODE HERE -----------\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127574ab",
   "metadata": {},
   "source": [
    "### Q1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a8fd27",
   "metadata": {},
   "source": [
    "Find trips which trip distances generate the highest tip percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def distance_with_most_tip(df):\n",
    "    '''\n",
    "    input: df a dataframe (PySpark DataFrame)\n",
    "    output: df a dataframe with following columns:\n",
    "            - trip_distance\n",
    "            - tip_percent\n",
    "            \n",
    "    trip_percent is the percent of tip out of fare_amount\n",
    "    '''\n",
    "\n",
    "    # START YOUR CODE HERE ---------\n",
    "    from pyspark.sql.functions import col, ceil, expr\n",
    "\n",
    "    df = df.filter((col(\"fare_amount\") > 2.00) & (col(\"trip_distance\") > 0))\n",
    "\n",
    "    df = df.withColumn(\"tip_percent\", expr(\"(tip_amount * 100) / fare_amount\"))\n",
    "\n",
    "    df = df.withColumn(\"trip_distance_rounded\", ceil(\"trip_distance\"))\n",
    "\n",
    "    df = df.groupBy(\"trip_distance_rounded\").agg(expr(\"avg(tip_percent)\").alias(\"tip_percent\"))\n",
    "\n",
    "    df = df.withColumnRenamed(\"trip_distance_rounded\", \"trip_distance\")\n",
    "\n",
    "    df = df.orderBy(col(\"tip_percent\").desc()).limit(15)\n",
    "\n",
    "    # END YOUR CODE HERE -----------\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0172fe6",
   "metadata": {},
   "source": [
    "### Q1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4613c906",
   "metadata": {},
   "source": [
    "Determine the average speed at different times of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abff9e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def time_with_most_traffic(df):\n",
    "    '''\n",
    "    input: df a dataframe\n",
    "    output: df a dataframe with following columns:\n",
    "            - time_of_day\n",
    "            - am_avg_speed\n",
    "            - pm_avg_speed\n",
    "            \n",
    "    am_avg_speed and pm_avg_speed are the average trip distance / average trip time calculated for each hour\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # START YOUR CODE HERE ---------\n",
    "    from pyspark.sql.functions import col, hour, avg, unix_timestamp, when, to_timestamp\n",
    "\n",
    "    # Convert datetime columns to timestamp type if they aren't already\n",
    "    df = df.withColumn(\"tpep_pickup_datetime\", to_timestamp(\"tpep_pickup_datetime\"))\n",
    "    df = df.withColumn(\"tpep_dropoff_datetime\", to_timestamp(\"tpep_dropoff_datetime\"))\n",
    "\n",
    "    # Calculate trip duration in hours\n",
    "    df = df.withColumn(\"trip_duration_hours\", \n",
    "                       (unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\")) / 3600)\n",
    "\n",
    "    # Extract hour from pickup time\n",
    "    df = df.withColumn(\"hour\", hour(\"tpep_pickup_datetime\"))\n",
    "\n",
    "    # Compute average distance and average duration by hour\n",
    "    df = df.groupBy(\"hour\").agg(\n",
    "        avg(\"trip_distance\").alias(\"avg_distance\"),\n",
    "        avg(\"trip_duration_hours\").alias(\"avg_duration\")\n",
    "    )\n",
    "\n",
    "    # Compute average speed\n",
    "    df = df.withColumn(\"avg_speed\", col(\"avg_distance\") / col(\"avg_duration\"))\n",
    "\n",
    "    # Convert hour to 12-hour time_of_day format (0 to 11 where 0 = 12 o'clock)\n",
    "    df = df.withColumn(\"time_of_day\", col(\"hour\") % 12)\n",
    "\n",
    "    # Separate into AM and PM speeds\n",
    "    df = df.withColumn(\"am_avg_speed\", when(col(\"hour\") < 12, col(\"avg_speed\")))\n",
    "    df = df.withColumn(\"pm_avg_speed\", when(col(\"hour\") >= 12, col(\"avg_speed\")))\n",
    "\n",
    "    # Aggregate by time_of_day to combine AM and PM values\n",
    "    df = df.groupBy(\"time_of_day\").agg(\n",
    "        avg(\"am_avg_speed\").alias(\"am_avg_speed\"),\n",
    "        avg(\"pm_avg_speed\").alias(\"pm_avg_speed\")\n",
    "    ).orderBy(\"time_of_day\")\n",
    "\n",
    "    # END YOUR CODE HERE -----------\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40b4e83-0f93-4637-bc3b-34f9fbb9f249",
   "metadata": {},
   "source": [
    "## The below cells are for you to investigate your solutions and will not be graded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b238c9-7bc7-458a-a3d8-8ce2d686418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()\n",
    "df = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbab81e-2317-4b4e-b25a-88f3110a94f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_pair(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7dd12b-4b60-407b-9c52-5b7cb2082cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_with_most_tip(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02723df-2490-4234-9292-eea7cebb08ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_with_most_traffic(df).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
